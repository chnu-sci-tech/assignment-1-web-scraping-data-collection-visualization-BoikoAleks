{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks for laboratory assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports section\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract webpage data given the url\n",
    "\n",
    "Create a Python script that performs basic web scraping on a page to extract all the information into text and returns it as a string.\n",
    "String should not contain tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_web_page(url):\n",
    "    \"\"\"\n",
    "    Fetch the contentof the given web page.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the web page to fetch.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the page as a string.\n",
    "\n",
    "    Raises:\n",
    "        HTTPError: If the HTTP request returned an unsuccessful status code.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status() \n",
    "    response_text = BeautifulSoup(response.text).get_text().strip()\n",
    "    return response_text\n",
    "\n",
    "print(parse_web_page('https://fmi.chnu.edu.ua/')[:255])\n",
    "print(parse_web_page('https://en.wikipedia.org/wiki/Web_scraping')[:255])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Головна - Факультет математики та інформатики\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Перейти до основного вмісту\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[email protected]\n",
    "\n",
    "\n",
    "\n",
    "                58012, Україна, м. Чернівці, вул. Університетська, 28\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Web scraping - Wikipedia\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Jump to content\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Main menu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Main menu\n",
    "move to sidebar\n",
    "hide\n",
    "\n",
    "\n",
    "\n",
    "                Navigation\n",
    "\n",
    "\n",
    "\n",
    "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                Contribute\n",
    "\n",
    "\n",
    "\n",
    "HelpLearn to editComm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from the API\n",
    "\n",
    "Create a python script that performs basic request to API endpoint and saves that data to a JSON file `result.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_api(api_url):\n",
    "    \"\"\"\n",
    "    Fetch the data of the given API endpoint and save it to result.json.\n",
    "\n",
    "    Args:\n",
    "        api_url (str): The URL of the API endpoint.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "\n",
    "    Raises:\n",
    "        HTTPError: If the HTTP request returned an unsuccessful status code.\n",
    "    \"\"\"\n",
    "    try:\n",
    "       \n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        # Save the data to result.json\n",
    "        with open('result.json', 'w') as json_file:\n",
    "            json.dump(data, json_file, indent=4)\n",
    "        \n",
    "        print(\"Data saved to result.json\")\n",
    "\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred: {err}\")\n",
    "\n",
    "parse_api('https://api.github.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the json file\n",
    "\n",
    "Parse the `weather.json` file and return weather data for a specific date, that is given as a parameter. Return the data as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(date:str) -> list:\n",
    "    \"\"\"\n",
    "    Parse the data from weather.json file and return weather data for a given date.\n",
    "\n",
    "    Args:\n",
    "        date (str): The date for which we look up the weather.\n",
    "\n",
    "    Returns:\n",
    "        list: a list of weather data for a given date.\n",
    "    \"\"\"\n",
    "    with open(\"E:/Универ/5 kyrs/sci-tech/assignment-1-web-scraping-data-collection-visualization-BoikoAleks/resources/weather.json\") as f:\n",
    "        weather_data = json.load(f)\n",
    "    for weather in weather_data['daily']:\n",
    "        if weather.get(\"date\",\"\") == date:\n",
    "            return list(weather.values())\n",
    "    return []\n",
    "    \n",
    "target_date = '2024-8-19'\n",
    "print(parse_json(target_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['2024-08-19', 30.0, 21.0, 5.0, 10.0, 70, 'Light rain']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the csv file\n",
    "\n",
    "Parse the `weather.csv` file and return weather data for a specific date, that is given as a parameter. Return the data as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv(date):\n",
    "    \"\"\"\n",
    "    Parse the data from weather.csv file and return weather data for a given date.\n",
    "\n",
    "    Args:\n",
    "        date (str): The date for which we look up the weather.\n",
    "\n",
    "    Returns:\n",
    "        list: a list of weather data for a given date.\n",
    "    \"\"\"\n",
    "    weather_data = pd.read_csv(\"E:/Универ/5 kyrs/sci-tech/assignment-1-web-scraping-data-collection-visualization-BoikoAleks/resources/weather.csv\", delimiter=\",\")\n",
    "    filtered_data = weather_data[weather_data['CET'] == date] # dataframe if (weather_data['CET'] == date) - True\n",
    "    if not filtered_data.empty:\n",
    "        return(filtered_data.values)\n",
    "    return []\n",
    "    \n",
    "target_date = '1997-5-22'\n",
    "print(parse_csv(target_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[['1997-5-22' 25.0 18.0 10.0 11.0 8.0 6.0 88.0 54.0 34.0 1017 1015 1012\n",
    "  10.0 10.0 10.0 11 3 nan 0.0 3.0 nan 277]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data\n",
    "\n",
    "Visualize the `weather.csv` data using matplotlib. Choose your own approach to data visualization. Save the results (as `.png`, `.webp` files etc., your choise) in this repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data()-> None:\n",
    "    \"\"\"\n",
    "    Parse the data from weather.csv file and visualize it using Matplotlib. Use more then one visualization. \n",
    "    Save the results in the repository.\n",
    "\n",
    "    Args:\n",
    "        None: None.\n",
    "\n",
    "    Returns:\n",
    "        None: None.\n",
    "    \"\"\"\n",
    "    weather_data = pd.read_csv(\"E:/Универ/5 kyrs/sci-tech/assignment-1-web-scraping-data-collection-visualization-BoikoAleks/resources/weather.csv\", delimiter=\",\", nrows=50)\n",
    "    plt.plot(weather_data['CET'],weather_data['WindDirDegrees'])\n",
    "\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"WindDirDegrees\")\n",
    "    plt.savefig(\"result/visibility.png\")\n",
    "    plt.show()\n",
    "\n",
    "visualize_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
